{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n",
       "       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n",
       "       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n",
       "       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n",
       "       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour chaque image, 8 * 8\n",
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C = 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(digits.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "clf = svm.SVC()\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)  \n",
    "\n",
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0])\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pkl')\n",
    "clf = joblib.load('filename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "rng = np.random.RandomState(0)\n",
    "# rand(a,b) : taille a * b, tous les chiffres sont des chiffres produit aléatoire entre 0 et 1\n",
    "X = rng.rand(10,2000)\n",
    "X = np.array(X,dtype='float32')\n",
    "print X.dtype\n",
    "\n",
    "# 高斯随机映射 Gaussian random projection \n",
    "# sklearn.random_projection.GaussianRandomProjection \n",
    "# 通过将原始输入空间投影在随机生成的矩阵上来降低维度\n",
    "transformer = random_projection.GaussianRandomProjection()\n",
    "X_new = transformer.fit_transform(X)\n",
    "print X_new.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "['setosa', 'setosa', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "iris = datasets.load_iris()\n",
    "clf = SVC()\n",
    "clf.fit(iris.data, iris.target)\n",
    "print list(clf.predict(iris.data[:3]))\n",
    "clf.fit(iris.data, iris.target_names[iris.target])\n",
    "print list(clf.predict(iris.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.rand(100, 10)\n",
    "# binomial(n, p, size = None) n : 个数 p : 概率 \n",
    "Y = rng.binomial(1,0.5,100)\n",
    "X_test = rng.rand(5,10)\n",
    "clf = SVC()\n",
    "clf.set_params(kernel = 'linear').fit(X,Y)\n",
    "clf.predict(X_test)\n",
    "# rbf 径向基函数\n",
    "clf.set_params(kernel='rbf').fit(X,Y)\n",
    "clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# 上面的代码测试了svm在OneVsRestClassifier的包装\n",
    "# 分别处理多分类和多标签的情况。\n",
    "# 特别注意，在多标签的情况下，输入必须是二值化的。\n",
    "# 所以需要MultiLabelBinarizer()先处理。\n",
    "X = [[1,2],[2,4],[4,5],[3,2],[3,1]]\n",
    "y = [0,0,1,1,2]\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "classif.fit(X,y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = LabelBinarizer().fit_transform(y)\n",
    "classif.fit(X,y).predict(X)\n",
    "# line 4 and 5 = 0, it means the data is not matched to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "classif.fit(X,y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b42d150>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "#Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "#Display the first digit\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 3 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# pylab.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "# images_and_labels stocke 2 élément\n",
    "# une liste conenant des valeur de pixels 8*8\n",
    "# label de l'image\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2,4,index + 1)\n",
    "    plt.axis('off')\n",
    "    #plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    #plt.title('trainging : %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "# nb samples\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples / 2:]\n",
    "predicted = classifier.predict(data[n_samples / 2:])\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "images_and_predictions = list(zip(digits.images[n_samples / 2:], predicted))\n",
    "\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "# print data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119702750>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits.images.shape\n",
    "import pylab as pl\n",
    "pl.imshow(digits.images[-1], cmap=pl.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape(a,b) : a lignes b colonne\n",
    "# si b = -1, alors selon le nb de lignes a pour reformer la liste\n",
    "data = digits.images.reshape((digits.images.shape[0],-1))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split iris data in train and test data\n",
    "# A random permutation, to split the data randomly\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]\n",
    "\n",
    "# Create and fit a nearest-neighbor classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train) \n",
    "knn.predict(iris_X_test)\n",
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X_train = diabetes.data[:-20]\n",
    "diabetes_X_test = diabetes.data[-20:]\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.03499549e-01  -2.37639315e+02   5.10530605e+02   3.27736980e+02\n",
      "  -8.14131709e+02   4.92814588e+02   1.02848452e+02   1.84606489e+02\n",
      "   7.43519617e+02   7.60951722e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58507530226905724"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(diabetes_X_train,diabetes_y_train)\n",
    "print(regr.coef_)\n",
    "# The mean square error\n",
    "np.mean((regr.predict(diabetes_X_test)-diabetes_y_test)**2)\n",
    "# explained variance score : 1 is perfect prediction\n",
    "# and 0 means that there is no linear relationship between X and y\n",
    "regr.score(diabetes_X_test, diabetes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  如果每一维的数据点很少，噪声将会造成很大的偏差影响：\n",
    "X = np.c_[.5, 1].T\n",
    "y = [.5, 1]\n",
    "test = np.c_[0, 2].T\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "np.random.seed(0)\n",
    "for _ in range(6):\n",
    "    this_X = .1 * np.random.normal(size=(2,1)) + X\n",
    "    regr.fit(this_X, y)\n",
    "    pl.plot(test, regr.predict(test))\n",
    "    pl.scatter(this_X, y, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 高维统计学习的一个解决方案是将回归系数缩小到0：\n",
    "# 观测数据中随机选择的两个数据集近似不相关。\n",
    "# 这被称为岭回归（Ridge Regression）\n",
    "# alpha 正则化强度; 必须是正浮点数\n",
    "regr = linear_model.Ridge(alpha=.1)\n",
    "pl.figure()\n",
    "for _ in range(6):\n",
    "    this_X = .1*np.random.normal(size=(2,1)) + X\n",
    "    regr.fit(this_X,y)\n",
    "    pl.plot(test,regr.predict(test))\n",
    "    pl.scatter(this_X, y, s=3)\n",
    "    \n",
    "# 这是一个偏差/方差（bias/variance）的权衡：\n",
    "# 岭α参数越大，偏差（bias)越大，方差（variance）越小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58511106838835314, 0.58520730154446743, 0.58546775406984919, 0.58555120365039148, 0.58307170855541623, 0.57058999437280089]\n"
     ]
    }
   ],
   "source": [
    "# 我们可以选择α以最小化排除错误，这里使用糖尿病数据集而不是人为制造的数据：\n",
    "alphas = np.logspace(-4, -1, 6)\n",
    "from __future__ import print_function\n",
    "print ([regr.set_params(alpha = alpha).\n",
    "        fit(diabetes_X_train,diabetes_y_train,).\n",
    "        score(diabetes_X_test, diabetes_y_test)\n",
    "       for alpha in alphas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.         -212.43764548  517.19478111  313.77959962 -160.8303982    -0.\n",
      " -187.19554705   69.38229038  508.66011217   71.84239008]\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.Lasso()\n",
    "scores = [regr.set_params(alpha=alpha\n",
    "            ).fit(diabetes_X_train, diabetes_y_train\n",
    "            ).score(diabetes_X_test, diabetes_y_test)\n",
    "       for alpha in alphas]\n",
    "best_alpha = alphas[scores.index(max(scores))]\n",
    "regr.alpha = best_alpha\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于分类问题，比如iris标定任务，线性回归不是正确的方法。\n",
    "# 因为它会给数据得出大量远离决策边界的权重。\n",
    "# 一个线性方法是你和一个sigmoid函数或者logistic函数：\n",
    "logistic = linear_model.LogisticRegression(C = 1e5)\n",
    "logistic.fit(iris_X_train, iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.961111\n",
      "LogisticRegression score: 0.938889\n"
     ]
    }
   ],
   "source": [
    "# 通过Logistic回归进行收缩和稀疏：\n",
    "# 在LogisticRegression对象中C参数控制着正则化的数量：\n",
    "# C越大，正则化数目越少。\n",
    "# penalty= \"12\" 提供收缩（非稀疏化系数），\n",
    "# penalty=\"11\"提供稀疏化\n",
    "\n",
    "# 尝试使用近邻算法和线性模型对数字数据集进行分类。\n",
    "# 留出最后的10%作为测试集用来测试预测的精确度。\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "n_samples = len(X_digits)\n",
    "X_train = X_digits[:.9 * n_samples]\n",
    "y_train = y_digits[:.9 * n_samples]\n",
    "X_test = X_digits[.9 * n_samples:]\n",
    "y_test = y_digits[.9 * n_samples:]\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 支持向量机属于判别模型家族：\n",
    "# 它们尝试寻找样例的一个组合，构建一个两类之间的最大边缘平面。\n",
    "# 通过C参数进行正则化：\n",
    "# 一个较小的C意味着边缘是通过分割线周围的\n",
    "# 所有观测样例进行计算得到的（更规整化，正则化）；\n",
    "# 一个较大的C意味着边缘是通过邻近分割线的观测样例计算得到的\n",
    "#（更少的规整化，正则化）：\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(iris_X_train, iris_y_train)\n",
    "\n",
    "# 使用核函数 : kernel 在特征空间中类别不经常是线性(linear)可分的。\n",
    "# 解决方案是构建一个非线性但能用多项式代替的决策函数。\n",
    "# 这要通过核技巧实现：\n",
    "# 使用核可以被看作通过设置核在观测样例上创建决策力量。\n",
    "\n",
    "# 线性核：linear\n",
    "# 多项式核：\n",
    "# 径向基函数核（RBF,Radial Basis Function）：\n",
    "# 径向基函数是一个取值仅仅依赖于离原点距离的实值函数\n",
    "# 也就是Φ（x）=Φ(‖x‖),或者还可以是到任意一点c的距离\n",
    "svc = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================\n",
      "SVM Exercise\n",
      "================================\n",
      "A tutorial exercise for using different SVM kernels.\n",
      "This exercise is used in the :ref:`using_kernels_tut` part of the\n",
      ":ref:`supervised_learning_tut` section of the :ref:`stat_learn_tut_index`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:25: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================\n",
    "SVM Exercise\n",
    "================================\n",
    "A tutorial exercise for using different SVM kernels.\n",
    "This exercise is used in the :ref:`using_kernels_tut` part of the\n",
    ":ref:`supervised_learning_tut` section of the :ref:`stat_learn_tut_index`.\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X = X[y != 0, :2] # :2, 取第0 第1行\n",
    "y = y[y !=0]\n",
    "n_sample = len(X)\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_samples)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "X_train = X[:.9 * n_sample]\n",
    "y_train = y[:.9 * n_sample]\n",
    "X_test = X[.9 * n_sample:]\n",
    "y_test = y[.9 * n_sample:]\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    # catter可用于描绘散点图\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired)\n",
    "    # Circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none', zorder=10)\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    # mgrid : 是k（x轴）、b（y轴）以及ErrorArray（z轴）\n",
    "    #【step1：k扩展】(朝右扩展)：\n",
    "    #【step2：b扩展】(朝下扩展)： \n",
    "    #【step3：定位（ki，bi）】（把上面的k、b联合起来）： \n",
    "    #【step4：将（ki，bi）代入f(k,b)=3k^2+2b+1求f(ki,bi)】 \n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    \n",
    "    # decision_function_shape ： \n",
    "    # ‘ovo’ 一对一, ‘ovr’ 多对多  or None 无, default=None\n",
    "    # ravel : 返回一个连续的平坦数组\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "    plt.title(kernel)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93489148580968284, 0.95659432387312182, 0.93989983305509184]\n"
     ]
    }
   ],
   "source": [
    "# （1）分数，和交叉验证分数\n",
    "from sklearn import datasets, svm\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "svc = svm.SVC(C = 1, kernel= 'linear')\n",
    "svc.fit(X_digits[:-100], y_digits[:-100]).score(X_digits[-100:],y_digits[-100:])\n",
    "\n",
    "# 为了获得一个更好的预测精确度度量\n",
    "# 我们可以把我们使用的数据折叠交错地分成训练集和测试集：\n",
    "import numpy as np\n",
    "X_folds = np.array_split(X_digits, 3)\n",
    "y_folds = np.array_split(y_digits, 3)\n",
    "\n",
    "scores = list()\n",
    "for k in range(3) : \n",
    "    # We use 'list' to copy, in order to 'pop' later on\n",
    "    X_train = list(X_folds)\n",
    "    # pop() 函数用于移除列表中的一个元素（默认最后一个元素)\n",
    "    # 并且返回该元素的值。\n",
    "    # le kième element : ici est une liste\n",
    "    X_test = X_train.pop(k)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = list(y_folds)\n",
    "    y_test = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2 3 4 5] | test: [0 1]\n",
      "Train: [0 1 4 5] | test: [2 3]\n",
      "Train: [0 1 2 3] | test: [4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93489149,  0.95659432,  0.93989983])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉验证生成器\n",
    "from sklearn import cross_validation\n",
    "k_fold = cross_validation.KFold(n=6, n_folds=3)\n",
    "for train_indices, test_indices in k_fold:\n",
    "    print ('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "\n",
    "kfold = cross_validation.KFold(len(X_digits),n_folds=3)\n",
    "[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test],\n",
    "                                                y_digits[test])\n",
    "    for train, test in kfold]\n",
    "\n",
    "cross_validation.cross_val_score(svc, X_digits, y_digits, cv=kfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
